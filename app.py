import streamlit as st
import google.generativeai as genai
from openai import OpenAI
from openpyxl import load_workbook
from openpyxl.styles import Alignment
import io
from PIL import Image
import concurrent.futures

# ==========================================
# ãƒšãƒ¼ã‚¸è¨­å®š
# ==========================================
st.set_page_config(
    page_title="è‡´çŸ¥èª­æ›¸æ„Ÿæƒ³æ–‡ã‚¢ãƒ—ãƒª v5.2",
    layout="wide",
    page_icon="ğŸ“–"
)

# ==========================================
# ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šã‚¨ãƒªã‚¢: éå»ã®æ–‡ä½“å­¦ç¿’ã€‘
# ==========================================
PAST_REVIEWS = """
ï¼ˆä¾‹ï¼šéå»ã®æ„Ÿæƒ³æ–‡ï¼‰
ä»Šæœˆã®è‡´çŸ¥ã‚’èª­ã‚“ã§ã€ç‰¹ã«ã€Œé€†å¢ƒã“ããŒäººã‚’è‚²ã¦ã‚‹ã€ã¨ã„ã†è¨€è‘‰ãŒèƒ¸ã«åˆºã•ã‚Šã¾ã—ãŸã€‚
æ—¥ã€…ã®ç¨ç†å£«è£œåŠ©æ¥­å‹™ã«ãŠã„ã¦ã€ç¹å¿™æœŸã«ã¯ã¤ã„æ„šç—´ãŒå‡ºãã†ã«ãªã‚Šã¾ã™ãŒã€
ãã‚Œã¯è‡ªåˆ†ã®é­‚ã‚’ç£¨ãç ¥çŸ³ãªã®ã ã¨æ°—ã¥ã‹ã•ã‚Œã¾ã—ãŸã€‚
ãŠå®¢æ§˜ã®è©¦ç®—è¡¨ã‚’ä½œã‚‹ä½œæ¥­ä¸€ã¤ã¨ã£ã¦ã‚‚ã€ãã“ã«é­‚ã‚’è¾¼ã‚ã‚‹ã“ã¨ã€‚
ãã‚ŒãŒãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã¨ã—ã¦ã®æµå„€ã ã¨æ„Ÿã˜ã¾ã™ã€‚
"""

# Excelæ›¸ãè¾¼ã¿è¨­å®š
EXCEL_START_ROW = 9
CHARS_PER_LINE = 40

# ==========================================
# APIè¨­å®š (ã‚µã‚¤ãƒ‰ãƒãƒ¼)
# ==========================================
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    openai_key = st.secrets.get("OPENAI_API_KEY")
    if not openai_key:
        openai_key = st.text_input("OpenAI API Key", type="password")
    
    google_key = st.secrets.get("GOOGLE_API_KEY")
    if not google_key:
        google_key = st.text_input("Google API Key", type="password")

    client = None
    if openai_key:
        try:
            client = OpenAI(api_key=openai_key)
        except:
            st.error("OpenAIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™")

    if google_key:
        try:
            genai.configure(api_key=google_key)
        except:
            st.error("Googleã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™")

    st.markdown("---")
    uploaded_template = st.file_uploader("æ„Ÿæƒ³æ–‡ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ(.xlsx)", type=["xlsx"])
    target_length = st.selectbox("ç›®æ¨™æ–‡å­—æ•°", [300, 400, 500, 600, 700, 800], index=1)
    
    st.markdown("---")
    st.caption("ğŸ”§ OCRãƒ¢ãƒ‡ãƒ«è¨­å®š")
    model_main = st.text_input("ãƒ¡ã‚¤ãƒ³Model ID", value="gemini-3-flash-preview")
    model_sub = st.text_input("ã‚µãƒ–Model ID", value="gemini-2.0-flash-lite-preview-02-05")

    if st.button("ğŸ—‘ï¸ ãƒªã‚»ãƒƒãƒˆ"):
        for key in st.session_state.keys():
            del st.session_state[key]
        st.rerun()

# ==========================================
# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
# ==========================================
if "ocr_results" not in st.session_state:
    st.session_state.ocr_results = {"main": "", "sub1": "", "sub2": ""}
if "current_draft" not in st.session_state:
    st.session_state.current_draft = ""
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "selected_article_key" not in st.session_state:
    st.session_state.selected_article_key = "main"

# ==========================================
# é–¢æ•°å®šç¾©
# ==========================================
def split_text(text, chunk_size):
    if not text: return []
    clean_text = text.replace('\n', 'ã€€')
    return [clean_text[i:i+chunk_size] for i in range(0, len(clean_text), chunk_size)]

def process_ocr_task_safe(label, pil_images, model_id):
    """
    ã€OCRé–¢æ•°ã€‘ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèªè­˜å¼·åŒ–ç‰ˆ
    """
    if not pil_images:
        return ""
    
    try:
        gemini_inputs = []
        system_prompt = (
            "ã‚ãªãŸã¯é«˜ç²¾åº¦ãªOCRã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚é›‘èªŒã€è‡´çŸ¥ã€ã®ç´™é¢ã‚’èª­ã¿å–ã‚Šã¾ã™ã€‚\n"
            "ã€é‡è¦ãƒ«ãƒ¼ãƒ«ã€‘\n"
            "1. ç”»åƒå…¨ä½“ã‚’è¦‹ã¦ã€ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼ˆæ®µçµ„ã¿ï¼‰ã‚’èªè­˜ã—ã¦ãã ã•ã„ã€‚\n"
            "2. è¨˜äº‹ã®ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆæ„å‘³ã®ã¾ã¨ã¾ã‚Šï¼‰ã”ã¨ã«èª­ã¿é€²ã‚ã¦ãã ã•ã„ã€‚\n"
            "3. ç¸¦æ›¸ãã®æ®µçµ„ã¿ãŒã‚ã‚‹å ´åˆã€å³ã®æ®µã‹ã‚‰å·¦ã®æ®µã¸ã¨é †ç•ªã«èª­ã¿ã€æ®µã‚’ã¾ãŸã„ã§ä¸€è¡Œã¨ã—ã¦èª­ã¾ãªã„ã‚ˆã†ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚\n"
            "4. è¤‡æ•°ã®è¨˜äº‹ãŒã‚ã‚‹å ´åˆã¯ã€è¨˜äº‹ã”ã¨ã«åŒºåˆ‡ã£ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚\n"
            "5. å‡ºåŠ›å½¢å¼: [ç”»åƒç•ªå·] <æœ¬æ–‡>..."
        )
        gemini_inputs.append(system_prompt)
        
        for i, img in enumerate(pil_images):
            gemini_inputs.append(f"\n\n[ç”»åƒ{i+1}æšç›®]\n")
            gemini_inputs.append(img)
        
        model = genai.GenerativeModel(model_id)
        response = model.generate_content(gemini_inputs)
        return response.text
        
    except Exception as e:
        return f"[ã‚¨ãƒ©ãƒ¼: {label}ã®è§£æå¤±æ•—: {e}]"

def generate_draft(article_text, chat_context, target_len):
    """
    ã€ä¿®æ­£ç‰ˆã€‘æ„Ÿæƒ³æ–‡ç”Ÿæˆé–¢æ•°
    chat_contextï¼ˆå£æ‰“ã¡å†…å®¹ï¼‰ã®æœ‰ç„¡ã«ã‚ˆã£ã¦ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®Œå…¨ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã€‚
    ã“ã‚Œã«ã‚ˆã‚Šã€Œåˆç¨¿ã§ã®å¦„æƒ³ã€ã‚’é˜²ãã€ã€Œæ›¸ãç›´ã—ã€ã§ã®ç¢ºå®Ÿãªåæ˜ ã‚’å®Ÿç¾ã™ã‚‹ã€‚
    """
    if not client:
        return "ã‚¨ãƒ©ãƒ¼: OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"

    # ====================================================
    # ãƒ‘ã‚¿ãƒ¼ãƒ³A: åˆç¨¿ä½œæˆï¼ˆãƒãƒ£ãƒƒãƒˆãªã—ï¼‰
    # ====================================================
    if not chat_context:
        system_prompt = (
            "ã‚ãªãŸã¯ç¨ç†å£«äº‹å‹™æ‰€ã®è·å“¡ã§ã™ã€‚\n"
            "é›‘èªŒã€è‡´çŸ¥ã€ã®èª­æ›¸æ„Ÿæƒ³æ–‡ï¼ˆç¤¾å†…æœ¨é¶ä¼šç”¨ï¼‰ã®ã€åˆç¨¿ã€‘ã‚’ä½œæˆã—ã¾ã™ã€‚\n"
            "ä»¥ä¸‹ã®ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éå»ã®æ„Ÿæƒ³æ–‡ã€‘ã®æ–‡ä½“ã‚„ç†±é‡ã‚’æ¨¡å€£ã—ã€"
            "ã€è¨˜äº‹ã®å†…å®¹ã€‘ã‚’ãƒ™ãƒ¼ã‚¹ã«æ„Ÿæƒ³æ–‡ã‚’æ›¸ã„ã¦ãã ã•ã„ã€‚\n"
            "**é‡è¦: ã¾ã å…·ä½“çš„ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã¯å…¥åŠ›ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€å‹æ‰‹ã«å…·ä½“çš„ãªä½“é¨“è«‡ã‚’å‰µä½œã—ãªã„ã§ãã ã•ã„ã€‚**\n"
            "æ¥­å‹™ã¸ã®çµã³ã¤ã‘ã¯ã€Œæ—¥ã€…ã®æ¥­å‹™ã«ãŠã„ã¦ã€œã€ã¨ã„ã£ãŸä¸€èˆ¬çš„ãªè¡¨ç¾ã«ç•™ã‚ã¦ãã ã•ã„ã€‚"
        )
        user_content = (
            f"ã€ä»Šå›é¸æŠã—ãŸè¨˜äº‹ã®OCRãƒ‡ãƒ¼ã‚¿ã€‘\n{article_text}\n\n"
            f"ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éå»ã®æ„Ÿæƒ³æ–‡ï¼ˆæ–‡ä½“è¦‹æœ¬ï¼‰ã€‘\n{PAST_REVIEWS}\n\n"
            "ã€åŸ·ç­†æ¡ä»¶ã€‘\n"
            f"- æ–‡å­—æ•°ï¼š{target_len}æ–‡å­—å‰å¾Œ\n"
            "- æ–‡ä½“ï¼šã€Œã§ã™ãƒ»ã¾ã™ã€èª¿\n"
            "- æ®µè½ã”ã¨ã«æ”¹è¡Œã‚’å…¥ã‚Œã‚‹ã“ã¨ã€‚\n"
            "- æ§‹æˆï¼šâ‘ è¨˜äº‹ã®å¼•ç”¨ãƒ»è¦ç´„ â‘¡ä¸€èˆ¬çš„ãªæ¥­å‹™ã¸ã®æ°—ã¥ãï¼ˆâ€»å‰µä½œã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ç¦æ­¢ï¼‰ â‘¢ä»Šå¾Œã®æ±ºæ„"
        )

    # ====================================================
    # ãƒ‘ã‚¿ãƒ¼ãƒ³B: æ›¸ãç›´ã—ï¼ˆå£æ‰“ã¡åæ˜ ï¼‰
    # ====================================================
    else:
        system_prompt = (
            "ã‚ãªãŸã¯ç¨ç†å£«äº‹å‹™æ‰€ã®è·å“¡ã§ã™ã€‚\n"
            "èª­æ›¸æ„Ÿæƒ³æ–‡ã®ã€æ›¸ãç›´ã—ã€‘ã‚’è¡Œã„ã¾ã™ã€‚\n"
            "ã“ã‚Œã¾ã§ã®æ„Ÿæƒ³æ–‡ï¼ˆã¾ãŸã¯è¨˜äº‹å†…å®¹ï¼‰ã«ã€**ã€å£æ‰“ã¡ãƒãƒ£ãƒƒãƒˆã§ã®è¿½åŠ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã€‘ã‚’å…·ä½“çš„ã«çµ„ã¿è¾¼ã‚“ã§ãã ã•ã„ã€‚**\n"
            "æŠ½è±¡çš„ã ã£ãŸã€Œæ¥­å‹™ã¸ã®æ°—ã¥ãã€ã®éƒ¨åˆ†ã‚’ã€ãƒãƒ£ãƒƒãƒˆã§èªã‚‰ã‚ŒãŸã€Œå…·ä½“çš„ãªä½“é¨“è«‡ã€ã«å®Œå…¨ã«å·®ã—æ›¿ãˆã¦ãã ã•ã„ã€‚"
        )
        user_content = (
            f"ã€è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã€‘\n{article_text}\n\n"
            f"ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éå»ã®æ„Ÿæƒ³æ–‡ï¼ˆæ–‡ä½“è¦‹æœ¬ï¼‰ã€‘\n{PAST_REVIEWS}\n\n"
            f"ã€å£æ‰“ã¡ãƒãƒ£ãƒƒãƒˆã§ã®è¿½åŠ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ï¼ˆâ€»ã“ã‚Œã‚’å¿…ãšæ›¸ãã“ã¨â€»ï¼‰ã€‘\n{chat_context}\n\n"
            "ã€åŸ·ç­†æ¡ä»¶ã€‘\n"
            f"- æ–‡å­—æ•°ï¼š{target_len}æ–‡å­—å‰å¾Œ\n"
            "- æ–‡ä½“ï¼šã€Œã§ã™ãƒ»ã¾ã™ã€èª¿\n"
            "- æ§‹æˆï¼šâ‘ è¨˜äº‹ã®å¼•ç”¨ â‘¡**ãƒãƒ£ãƒƒãƒˆã§å‡ºãŸå…·ä½“çš„ãªã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰** â‘¢ä»Šå¾Œã®æ±ºæ„\n"
        )
    
    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}],
        temperature=0.7
    )
    return response.choices[0].message.content

# ==========================================
# ãƒ¡ã‚¤ãƒ³ç”»é¢
# ==========================================
st.title("ğŸ“– è‡´çŸ¥èª­æ›¸æ„Ÿæƒ³æ–‡ã‚¢ãƒ—ãƒª v5.2 (åˆç¨¿/ãƒªãƒ©ã‚¤ãƒˆåˆ†é›¢ç‰ˆ)")
st.caption("Step 1: å…¨ä½“ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè§£æOCR â†’ Step 2: è¨˜äº‹é¸æŠãƒ»åŸ·ç­† â†’ Step 3: Excelå‡ºåŠ›")

tab1, tab2, tab3 = st.tabs(["1ï¸âƒ£ ç”»åƒè§£æ", "2ï¸âƒ£ è¨˜äº‹é¸æŠ & åŸ·ç­†", "3ï¸âƒ£ Excelå‡ºåŠ›"])

# ------------------------------------------------------------------
# Tab 1: ä¸¦åˆ—OCRå‡¦ç†
# ------------------------------------------------------------------
with tab1:
    st.subheader("Step 1. è¨˜äº‹ç”»åƒã®èª­ã¿è¾¼ã¿")
    st.info("ç”»åƒã‚’åˆ†å‰²ã›ãšã€AIã«ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆå…¨ä½“ã‚’èªè­˜ã•ã›ã‚‹ã“ã¨ã§æ­£ç¢ºã«èª­ã¿å–ã‚Šã¾ã™ã€‚")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown("#### ğŸ“‚ ãƒ¡ã‚¤ãƒ³è¨˜äº‹")
        files_main = st.file_uploader("ç”»åƒã‚’é¸æŠ", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True, key="f1")
    with col2:
        st.markdown("#### ğŸ“‚ è¨˜äº‹2")
        files_sub1 = st.file_uploader("ç”»åƒã‚’é¸æŠ", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True, key="f2")
    with col3:
        st.markdown("#### ğŸ“‚ è¨˜äº‹3")
        files_sub2 = st.file_uploader("ç”»åƒã‚’é¸æŠ", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True, key="f3")

    if st.button("ğŸš€ å…¨è¨˜äº‹ã‚’ä¸€æ‹¬è§£æ (ä¸¦åˆ—ã‚¹ã‚¿ãƒ¼ãƒˆ)", type="primary"):
        if not (files_main or files_sub1 or files_sub2):
            st.error("ç”»åƒãŒé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        elif not google_key:
            st.error("Google APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        else:
            with st.spinner("ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’è§£æã—ã¦èª­ã¿å–ã£ã¦ã„ã¾ã™..."):
                try:
                    images_main = [Image.open(f).convert("RGB") for f in files_main] if files_main else []
                    images_sub1 = [Image.open(f).convert("RGB") for f in files_sub1] if files_sub1 else []
                    images_sub2 = [Image.open(f).convert("RGB") for f in files_sub2] if files_sub2 else []

                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future_main = executor.submit(process_ocr_task_safe, "ãƒ¡ã‚¤ãƒ³è¨˜äº‹", images_main, model_main)
                        future_sub1 = executor.submit(process_ocr_task_safe, "è¨˜äº‹2", images_sub1, model_sub)
                        future_sub2 = executor.submit(process_ocr_task_safe, "è¨˜äº‹3", images_sub2, model_sub)
                        
                        st.session_state.ocr_results["main"] = future_main.result()
                        st.session_state.ocr_results["sub1"] = future_sub1.result()
                        st.session_state.ocr_results["sub2"] = future_sub2.result()
                    
                    st.success("âœ… è§£æå®Œäº†ï¼ '2ï¸âƒ£ è¨˜äº‹é¸æŠ & åŸ·ç­†' ã‚¿ãƒ–ã¸é€²ã‚“ã§ãã ã•ã„ã€‚")
                except Exception as e:
                    st.error(f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    with st.expander("OCRè§£æçµæœã‚’ç¢ºèªã™ã‚‹"):
        st.text_area("Main", st.session_state.ocr_results["main"], height=100)
        st.text_area("Sub1", st.session_state.ocr_results["sub1"], height=100)
        st.text_area("Sub2", st.session_state.ocr_results["sub2"], height=100)

# ------------------------------------------------------------------
# Tab 2: è¨˜äº‹é¸æŠ & åŸ·ç­† & å£æ‰“ã¡
# ------------------------------------------------------------------
with tab2:
    st.subheader("Step 2. åŸ·ç­†å¯¾è±¡ã®é¸æŠã¨å£æ‰“ã¡")
    
    options_map = {"main": "ãƒ¡ã‚¤ãƒ³è¨˜äº‹", "sub1": "è¨˜äº‹2", "sub2": "è¨˜äº‹3"}
    valid_options = [k for k, v in st.session_state.ocr_results.items() if len(v) > 10]
    
    if not valid_options:
        st.warning("OCRãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚Tab 1ã§è§£æã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
        selected_article_text = ""
    else:
        selected_key = st.radio("å¯¾è±¡è¨˜äº‹ã‚’é¸æŠ", valid_options, format_func=lambda x: options_map[x], horizontal=True)
        selected_article_text = st.session_state.ocr_results[selected_key]
        
        if selected_key != st.session_state.selected_article_key:
            st.session_state.selected_article_key = selected_key
            st.toast(f"{options_map[selected_key]} ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸ")

    st.markdown("---")

    col_draft, col_chat = st.columns([1, 1])

    with col_draft:
        st.markdown("### ğŸ“ æ„Ÿæƒ³æ–‡ãƒ‰ãƒ©ãƒ•ãƒˆ")
        
        # åˆç¨¿ä½œæˆãƒœã‚¿ãƒ³
        if st.button("ğŸš€ åˆç¨¿ã‚’ä½œæˆã™ã‚‹", disabled=(not selected_article_text)):
            if not client:
                 st.error("OpenAI APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                with st.spinner("åˆç¨¿ã‚’ä½œæˆä¸­ï¼ˆã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã¯ã¾ã å…¥ã‚Œã¾ã›ã‚“ï¼‰..."):
                    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ
                    st.session_state.chat_history = [] 
                    # ç¬¬2å¼•æ•°ã‚’Noneã«ã™ã‚‹ã“ã¨ã§ã€Œåˆç¨¿ãƒ¢ãƒ¼ãƒ‰ã€ã«ã™ã‚‹
                    draft = generate_draft(selected_article_text, None, target_length)
                    st.session_state.current_draft = draft
                    
                    # AIã‹ã‚‰ã®æœ€åˆã®è³ªå•ã‚’å±¥æ­´ã«è¿½åŠ 
                    st.session_state.chat_history.append({
                        "role": "assistant", 
                        "content": "åˆç¨¿ã‚’ä½œæˆã—ã¾ã—ãŸï¼\nä»Šã®æ®µéšã§ã¯ä¸€èˆ¬çš„ãªå†…å®¹ã«ãªã£ã¦ã„ã¾ã™ã€‚\n\n**ã“ã®è¨˜äº‹ã®ãƒ†ãƒ¼ãƒã«é–¢é€£ã—ã¦ã€ã‚ãªãŸã®æ¥­å‹™ã§èµ·ããŸå…·ä½“çš„ãªå‡ºæ¥äº‹ï¼ˆæˆåŠŸãƒ»å¤±æ•—ãƒ»æ°—ã¥ãï¼‰ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚æ„Ÿæƒ³æ–‡ã«åæ˜ ã•ã›ã¾ã™ã€‚**"
                    })
                    st.rerun()
        
        if st.session_state.current_draft:
            st.text_area("ç¾åœ¨ã®åŸç¨¿", st.session_state.current_draft, height=600, key="draft_area")
            
            # æ›¸ãç›´ã—ãƒœã‚¿ãƒ³
            if st.button("ğŸ”„ ãƒãƒ£ãƒƒãƒˆã®å†…å®¹ã‚’åæ˜ ã—ã¦æ›¸ãç›´ã™", type="primary"):
                if not st.session_state.chat_history:
                    st.warning("ã¾ã ãƒãƒ£ãƒƒãƒˆã§ä¼šè©±ã—ã¦ã„ã¾ã›ã‚“ã€‚å³å´ã§ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’è©±ã—ã¦ãã ã•ã„ã€‚")
                else:
                    with st.spinner("ãƒãƒ£ãƒƒãƒˆã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’çµ„ã¿è¾¼ã‚“ã§ãƒªãƒ©ã‚¤ãƒˆä¸­..."):
                        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’æ–‡å­—åˆ—åŒ–
                        chat_context = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.chat_history])
                        
                        # ç¬¬2å¼•æ•°ã«ãƒãƒ£ãƒƒãƒˆå†…å®¹ã‚’æ¸¡ã™ã“ã¨ã§ã€Œæ›¸ãç›´ã—ãƒ¢ãƒ¼ãƒ‰ã€ã«ã™ã‚‹
                        new_draft = generate_draft(selected_article_text, chat_context, target_length)
                        st.session_state.current_draft = new_draft
                        st.success("æ›¸ãç›´ã—ã¾ã—ãŸï¼")
                        st.rerun()

    with col_chat:
        st.markdown("### ğŸ’¬ å£æ‰“ã¡")
        chat_container = st.container(height=500)
        
        for message in st.session_state.chat_history:
            with chat_container.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å…¥åŠ›..."):
            if not selected_article_text:
                st.error("å…ˆã«è¨˜äº‹ã‚’é¸æŠã—ã¦åˆç¨¿ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")
            elif not client:
                st.error("OpenAI APIã‚­ãƒ¼ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            else:
                st.session_state.chat_history.append({"role": "user", "content": prompt})
                with chat_container.chat_message("user"):
                    st.markdown(prompt)

                with chat_container.chat_message("assistant"):
                    with st.spinner("è€ƒãˆä¸­..."):
                        chat_sys = f"ã‚ãªãŸã¯ç·¨é›†è€…ã§ã™ã€‚ä»¥ä¸‹ã®è¨˜äº‹å†…å®¹ã‚’è¸ã¾ãˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰æ·±ã„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å¼•ãå‡ºã—ã¦ãã ã•ã„ã€‚\nè¨˜äº‹: {selected_article_text[:500]}..."
                        msgs = [{"role": "system", "content": chat_sys}] + st.session_state.chat_history
                        res = client.chat.completions.create(model="gpt-4o", messages=msgs)
                        ai_res = res.choices[0].message.content
                        
                st.markdown(ai_res)
                st.session_state.chat_history.append({"role": "assistant", "content": ai_res})

# ------------------------------------------------------------------
# Tab 3: Excelå‡ºåŠ›
# ------------------------------------------------------------------
with tab3:
    st.subheader("Step 3. Excelå‡ºåŠ›")
    
    if st.session_state.current_draft and uploaded_template:
        if st.button("ğŸ“¥ Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
            try:
                wb = load_workbook(uploaded_template)
                ws = wb.active
                for r in range(EXCEL_START_ROW, 100): ws[f"A{r}"].value = None
                lines = split_text(st.session_state.current_draft, CHARS_PER_LINE)
                for i, line in enumerate(lines):
                    cell = ws[f"A{EXCEL_START_ROW+i}"]
                    cell.value = line
                    cell.alignment = Alignment(wrap_text=False, shrink_to_fit=False, horizontal='left')
                out = io.BytesIO()
                wb.save(out)
                out.seek(0)
                st.download_button("Excelä¿å­˜", out, "æ„Ÿæƒ³æ–‡.xlsx", "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
                st.success("å®Œäº†ï¼")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
    else:
        st.info("æ„Ÿæƒ³æ–‡ã‚’ä½œæˆã—ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
